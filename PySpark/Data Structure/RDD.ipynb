{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5482313-64f9-424e-ab70-4f820a022886",
   "metadata": {},
   "source": [
    "### RDD object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66f7b032-7991-42eb-9307-361d2f528778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create entry points to spark\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "sc=SparkContext()\n",
    "spark = SparkSession(sparkContext=sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb2d087-7583-4399-9b75-a9f013139440",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-O58PAUC:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2457c627d10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174253e8-ad63-4c85-891f-2ecdb9119aef",
   "metadata": {},
   "source": [
    "#### Creating a Resilient Data Structure (RDD)\n",
    "\n",
    "There are two ways to create an RDD in PySpark. You can parallelize a list or read from a repository (a file or a database)\n",
    "\n",
    "The class pyspark.SparkContext creates a client which connects to a Spark cluster. This client can be used to create an RDD object.\n",
    "\n",
    "There are two ways to create an RDD in PySpark. You can parallelize a list or read from a repository (a file or a database) :\n",
    "\n",
    "- `parallelize()`\n",
    "\n",
    "- `textFile()`\n",
    "\n",
    "#### 1. parallelize()\n",
    "parallelize() distribute a local python collection to form an RDD. Common built-in python collections include **dict**, **list**, **tuple** or **set**.\n",
    "\n",
    "##### - From a Dict : \n",
    "Only the keys are used to form the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4bef5b1-bae5-4f46-8aaf-25d4890663a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x', 'y', 'z']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    'x': 10,\n",
    "    'y': 100,\n",
    "    'z': 1000\n",
    "}\n",
    "rdd = sc.parallelize(d)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a84209-6bb5-458d-8aa0-2837a1bf11c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### - From a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3aa8a3f6-6af0-48f7-992e-a3178cb1e0db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3cdb6-ce2b-45ee-8a3e-26677c39a609",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### - From a tuple or a list of tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b933d3f1-b5a0-4faa-9645-63b95a635707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12345, 6789, 'hello!']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize((12345, 6789, 'hello!'))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d650bd9f-451e-44b2-9d64-12d5b353315b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (3, 2, 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [(1, 2, 3), (3, 2, 1)] \n",
    "rdd = sc.parallelize(l)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31abd78e-c108-4f16-b69b-465a1b402378",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### - From a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18ffdf8d-07d9-4903-abd9-50cc44ac8645",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple', 'banana', 'orange', 'pear']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}\n",
    "rdd = sc.parallelize(basket)\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258d81cc-c61b-413a-8aa3-0723d3061caf",
   "metadata": {},
   "source": [
    "#### 2.  textFile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87861c1-9a67-457c-ad9a-bb1acaf3ec49",
   "metadata": {},
   "source": [
    "The textFile() function reads a text file and returns it as an RDD of strings. Usually, you will need to apply some map functions to transform each elements of the RDD to some data structure/type that is suitable for data analysis.\n",
    "\n",
    "When using textFile(), each each row from the file forms an element of an RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0afb64-3016-4e9e-b660-ce55af1660bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### - From a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cdd77d7-5f0b-428c-a85e-f2db17782597",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_from_file = sc.\\\n",
    "    textFile(\n",
    "        'datasets/Furniture Price Prediction.csv', \n",
    "        4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f1d089-6e64-490c-a1be-6dc4efa64c53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "pyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
